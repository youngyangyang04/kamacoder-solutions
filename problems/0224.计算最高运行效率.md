# 动态规划
[题目链接](https://kamacoder.com/problempage.php?pid=1304)
## 思路分析
**状态定义**：定义dp[i][j][k]为前i个算法中消耗了NPU的j的算力和GPU的k的算力所能拿到的最大的效率。

**状态转移**：对于第i个算法，有三种选择，选择使用CPU执行；如果它的算力要求小于等于NPU的算力容量，那么可以选择NPU执行；同理，如果他的算力要求小于等于GPU的容量，那么可以选择GPU执行。如果选择了GPU或者NPU执行的话，那么就可以获得相应的效率。

**状态转移**：设第i个算法的算力要求、NPU效率、GPU效率分别为x，y，z。
1. dp[i][j][k] = max(dp[i-1][j-x][k] + y, dp[i][j][k])，其中j >= x；
2. dp[i][j][k] = max(dp[i-1][j][k-x] + z, dp[i][j][k])，其中k >= x。

优化：由于当前状态只和前一个状态有关，可以根据背包的思路将第一个维度进行优化。
## 复杂度分析
1. 时间复杂度：O(nmk)；
2. 空间复杂度：O(km)。
## 代码实现
### Cpp
``` cpp
#include<bits/stdc++.h>
#define endl '\n'
const int N = 100005, MOD = 1000000007;
using namespace std;
using LL = long long;
using PIL = pair<int, LL>;
using PII = pair<int, int>;
using T3I = tuple<int, int, int>;
int dir[]{1, 0, -1, 0, 1};
int main() {
    cin.tie(nullptr) -> sync_with_stdio(false);
    int n, m, k;
    cin >> k >> m >> n;
    // k表示npu的数量，m表示gpu的数量，n表示算法的数量
    vector<T3I> vt;
    for (int i = 0, a, b, c; i < n; ++i) {
        cin >> a >> b >> c;
        vt.emplace_back(a, b, c);
    }
    vector<vector<int>> dp(k + 1, vector<int>(m + 1, 0));
    for (int i = n - 1; i >= 0; --i) {
        // 取出对应的算法参数
        auto [x, y, z] = vt[i];
        for (int j = k; j >= 0; --j) {
            for (int l = m; l >= 0; --l) {
                if (j >= x) dp[j][l] = max(dp[j][l], dp[j - x][l] + y);
                if (l >= x) dp[j][l] = max(dp[j][l], dp[j][l - x] + z);
            }
        }
    }
    cout << dp[k][m] << endl;
    return 0;
}
```
### Python
``` python
import sys

def max_performance(k, m, n, algorithms):
    # 创建 3D DP 数组
    dp = [[[0] * (m + 1) for _ in range(k + 1)] for _ in range(n + 1)]
    ans = 0

    # 倒序遍历算法
    for i in range(n - 1, -1, -1):
        x, y, z = algorithms[i]  # 取出当前算法的参数
        for j in range(k + 1):
            for l in range(m + 1):
                dp[i][j][l] = dp[i + 1][j][l]  # 不使用当前算法
                if j >= x:
                    dp[i][j][l] = max(dp[i][j][l], dp[i + 1][j - x][l] + y)  # 选择使用 NPU
                if l >= x:
                    dp[i][j][l] = max(dp[i][j][l], dp[i + 1][j][l - x] + z)  # 选择使用 GPU
                ans = max(ans, dp[i][j][l])  # 更新最大值
    
    return ans

if __name__ == "__main__":
    # 优化输入
    input = sys.stdin.read
    data = list(map(int, input().split()))
    
    k, m, n = data[:3]  # 读取 k, m, n
    algorithms = [tuple(data[i:i+3]) for i in range(3, len(data), 3)]  # 读取算法参数

    # 计算并输出最大性能
    print(max_performance(k, m, n, algorithms))

```
### Java
``` java
import java.io.*;
import java.util.*;

public class Main {
    public static int maxPerformance(int k, int m, int n, int[][] algorithms) {
        int[][][] dp = new int[n + 1][k + 1][m + 1];  // 3D DP 数组
        int ans = 0;

        for (int i = n - 1; i >= 0; i--) {
            int x = algorithms[i][0], y = algorithms[i][1], z = algorithms[i][2];
            for (int j = 0; j <= k; j++) {
                for (int l = 0; l <= m; l++) {
                    dp[i][j][l] = dp[i + 1][j][l];  // 不使用当前算法
                    if (j >= x) dp[i][j][l] = Math.max(dp[i][j][l], dp[i + 1][j - x][l] + y);  // 选择 NPU
                    if (l >= x) dp[i][j][l] = Math.max(dp[i][j][l], dp[i + 1][j][l - x] + z);  // 选择 GPU
                    ans = Math.max(ans, dp[i][j][l]);  // 更新最大值
                }
            }
        }
        return ans;
    }

    public static void main(String[] args) throws IOException {
        // 优化输入
        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
        StringTokenizer st = new StringTokenizer(br.readLine());
        
        int k = Integer.parseInt(st.nextToken());
        int m = Integer.parseInt(st.nextToken());
        int n = Integer.parseInt(st.nextToken());

        int[][] algorithms = new int[n][3];
        for (int i = 0; i < n; i++) {
            st = new StringTokenizer(br.readLine());
            algorithms[i][0] = Integer.parseInt(st.nextToken());
            algorithms[i][1] = Integer.parseInt(st.nextToken());
            algorithms[i][2] = Integer.parseInt(st.nextToken());
        }

        // 计算并输出最大性能
        System.out.println(maxPerformance(k, m, n, algorithms));
    }
}

```